# Cell Analyzer - Training Configuration

# Model Architecture
model:
  name: unet
  encoder: resnet34                    # resnet34, resnet50, efficientnet-b0, efficientnet-b3
  encoder_weights: imagenet            # Use ImageNet pretrained weights
  num_classes: 4                       # Background + 3 cell types
  input_size: 512                      # Input image size (512 or 1024)
  activation: null                     # null for logits, 'sigmoid' for binary, 'softmax' for multiclass

# Class Names (for visualization and export)
classes:
  0: background
  1: cell_type_a
  2: cell_type_b
  3: cell_type_c

# Training Parameters
training:
  epochs: 100
  batch_size: 4
  num_workers: 4
  pin_memory: true

  # Optimizer
  optimizer:
    type: adam                         # adam, adamw, sgd
    learning_rate: 0.0001
    weight_decay: 0.0001

  # Learning Rate Scheduler
  scheduler:
    type: cosine                       # cosine, step, plateau, none
    cosine_t_max: 100                  # For cosine annealing
    step_size: 30                      # For step scheduler
    gamma: 0.1                         # LR decay factor
    patience: 10                       # For plateau scheduler

  # Loss Function
  loss:
    type: combined                     # combined, dice, bce, focal
    dice_weight: 0.5
    bce_weight: 0.5
    focal_alpha: 0.25
    focal_gamma: 2.0

  # Early Stopping
  early_stopping:
    enabled: true
    patience: 15
    min_delta: 0.001

  # Mixed Precision Training
  amp: true                            # Automatic Mixed Precision (faster on modern GPUs)

# Data Augmentation
augmentation:
  enabled: true

  # Geometric Transforms
  horizontal_flip: 0.5
  vertical_flip: 0.5
  rotate_limit: 45
  rotate_prob: 0.5
  scale_limit: 0.1
  scale_prob: 0.3

  # Pixel Transforms
  brightness_limit: 0.2
  contrast_limit: 0.2
  brightness_contrast_prob: 0.5
  hue_saturation_value_prob: 0.3

  # Noise and Blur
  gaussian_blur_prob: 0.2
  gaussian_noise_prob: 0.2

  # Advanced
  elastic_transform_prob: 0.2
  grid_distortion_prob: 0.2
  optical_distortion_prob: 0.2

  # Normalization (ImageNet stats)
  normalize:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]

# Dataset
data:
  root_dir: ./data
  images_dir: images
  masks_dir: masks
  train_list: train.txt
  val_list: val.txt
  test_list: test.txt                  # Optional

  # Data split (if train/val lists don't exist)
  train_ratio: 0.8
  val_ratio: 0.2

  # Image format
  image_ext: ['.jpg', '.jpeg', '.png', '.tif', '.tiff']
  mask_ext: '.png'

# Validation
validation:
  frequency: 1                         # Validate every N epochs
  save_predictions: true
  num_visualization: 5                 # Number of samples to visualize

# Checkpoints
checkpoints:
  save_dir: ./checkpoints
  save_best: true
  save_last: true
  save_top_k: 3                        # Keep top K checkpoints
  monitor: val_iou                     # Metric to monitor
  mode: max                            # max or min

# Logging
logging:
  tensorboard: true
  tensorboard_dir: ./runs
  log_interval: 10                     # Log every N batches

# Hardware
device: cuda                           # cuda or cpu
seed: 42                               # Random seed for reproducibility

# Inference (for testing)
inference:
  confidence_threshold: 0.5
  nms_threshold: 0.3
  min_cell_size: 50
  max_cell_size: 1000
