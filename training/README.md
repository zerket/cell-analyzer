# Cell Analyzer - Neural Network Training

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è U-Net –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∫–ª–µ—Ç–æ–∫.

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

```bash
pip install -r requirements.txt
```

### –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
- PyTorch >= 2.0
- segmentation-models-pytorch
- albumentations (–∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)
- opencv-python
- numpy
- pillow
- tqdm
- tensorboard (–¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è)

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
training/
‚îú‚îÄ‚îÄ README.md                 # –≠—Ç–æ—Ç —Ñ–∞–π–ª
‚îú‚îÄ‚îÄ requirements.txt          # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îú‚îÄ‚îÄ dataset.py               # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
‚îú‚îÄ‚îÄ model.py                 # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ U-Net
‚îú‚îÄ‚îÄ train.py                 # –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ export_onnx.py           # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
‚îú‚îÄ‚îÄ cvat_utils.py            # –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å CVAT
‚îú‚îÄ‚îÄ augmentations.py         # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
‚îú‚îÄ‚îÄ utils.py                 # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
‚îú‚îÄ‚îÄ config.yaml              # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ images/              # –ò—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    ‚îú‚îÄ‚îÄ masks/               # –ú–∞—Å–∫–∏ (—Ä–∞–∑–º–µ—Ç–∫–∞ –∏–∑ CVAT)
    ‚îú‚îÄ‚îÄ train.txt            # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    ‚îî‚îÄ‚îÄ val.txt              # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
```

## Workflow: –û—Ç —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

### –®–∞–≥ 1: –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ CVAT

#### 1.1 –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –≤ CVAT

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CVAT –ª–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ https://app.cvat.ai
2. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç:
   - **Name**: Cell Detection Project
   - **Labels**:
     - `background` (class_id: 0)
     - `cell_type_a` (class_id: 1)
     - `cell_type_b` (class_id: 2)
     - `cell_type_c` (class_id: 3)
   - **Task type**: Instance Segmentation

#### 1.2 –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

```bash
# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤–∞—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫—É
cp /path/to/your/images/*.jpg data/images/
```

–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ CVAT —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.

#### 1.3 –†–∞–∑–º–µ—Ç–∫–∞

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
1. –í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç "Polygon" –∏–ª–∏ "Mask"
2. –û–±–≤–µ–¥–∏—Ç–µ –∫–æ–Ω—Ç—É—Ä—ã –∫–ª–µ—Ç–æ–∫
3. –ü—Ä–∏—Å–≤–æ–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –º–µ—Ç–∫—É (cell_type_a, cell_type_b, cell_type_c)
4. **–í–∞–∂–Ω–æ**: –†–∞–∑–º–µ—Ç—å—Ç–µ –í–°–ï –∫–ª–µ—Ç–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏

#### 1.4 –≠–∫—Å–ø–æ—Ä—Ç —Ä–∞–∑–º–µ—Ç–∫–∏

–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ —Ä–∞–∑–º–µ—Ç–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
- **Format**: COCO 1.0 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) –∏–ª–∏ Pascal VOC
- **Save images**: Yes

```bash
# –ü–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞, —Ä–∞—Å–ø–∞–∫—É–π—Ç–µ –∞—Ä—Ö–∏–≤
unzip annotations.zip -d data/
```

#### 1.5 –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π

```bash
# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è COCO -> –º–∞—Å–∫–∏ PNG
python cvat_utils.py --format coco --input data/annotations.json --output data/masks/

# –ò–ª–∏ Pascal VOC -> –º–∞—Å–∫–∏ PNG
python cvat_utils.py --format pascal_voc --input data/Annotations/ --output data/masks/
```

### –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ train/val split (80/20)
python dataset.py --prepare-split --data-dir data/ --train-ratio 0.8

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
python dataset.py --visualize --num-samples 5
```

### –®–∞–≥ 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `config.yaml`:

```yaml
# Training settings
model:
  encoder: resnet34          # resnet34, resnet50, efficientnet-b3
  encoder_weights: imagenet  # –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞
  num_classes: 4             # 1 (background) + 3 (—Ç–∏–ø–∞ –∫–ª–µ—Ç–æ–∫)
  input_size: 512            # 512 –∏–ª–∏ 1024

training:
  epochs: 100
  batch_size: 4              # –£–º–µ–Ω—å—à–∏—Ç–µ –µ—Å–ª–∏ –Ω–µ—Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏ GPU
  learning_rate: 0.0001
  optimizer: adam
  scheduler: cosine          # cosine, step, plateau

  # Loss weights
  loss:
    dice_weight: 0.5
    bce_weight: 0.5

  # Augmentations
  augmentation:
    enabled: true
    flip_prob: 0.5
    rotate_prob: 0.5
    brightness_contrast: true
    blur_prob: 0.2

data:
  train_images: data/images/
  train_masks: data/masks/
  train_list: data/train.txt
  val_list: data/val.txt

device: cuda                 # cuda –∏–ª–∏ cpu
save_dir: checkpoints/
tensorboard_dir: runs/
```

### –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

```bash
# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
python train.py --config config.yaml

# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞
python train.py --config config.yaml --resume checkpoints/best_model.pth

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ CPU (–º–µ–¥–ª–µ–Ω–Ω–æ!)
python train.py --config config.yaml --device cpu
```

#### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

```bash
# –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
tensorboard --logdir runs/

# –û—Ç–∫—Ä–æ–π—Ç–µ –≤ –±—Ä–∞—É–∑–µ—Ä–µ: http://localhost:6006
```

–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è:
- **Loss** (Dice + BCE): –¥–æ–ª–∂–µ–Ω —É–º–µ–Ω—å—à–∞—Ç—å—Å—è
- **IoU (Intersection over Union)**: –¥–æ–ª–∂–µ–Ω —Ä–∞—Å—Ç–∏ (> 0.7 —Ö–æ—Ä–æ—à–æ)
- **Precision/Recall**: –±–∞–ª–∞–Ω—Å —Ç–æ—á–Ω–æ—Å—Ç–∏
- **F1-score**: –æ–±—â–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞

### –®–∞–≥ 5: –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏

```bash
# –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ
python train.py --config config.yaml --evaluate --checkpoint checkpoints/best_model.pth

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
python train.py --config config.yaml --visualize --checkpoint checkpoints/best_model.pth
```

### –®–∞–≥ 6: –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX

```bash
# –≠–∫—Å–ø–æ—Ä—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
python export_onnx.py \
    --checkpoint checkpoints/best_model.pth \
    --output models/unet_cell_detector.onnx \
    --input-size 512 \
    --num-classes 4

# –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX –º–æ–¥–µ–ª–∏
python export_onnx.py \
    --checkpoint checkpoints/best_model.pth \
    --output models/unet_cell_detector.onnx \
    --test-image data/images/test.jpg
```

### –®–∞–≥ 7: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ CellAnalyzer

1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ .onnx —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:
   ```bash
   cp models/unet_cell_detector.onnx D:/github/cell-analyzer/models/
   ```

2. –í CellAnalyzer:
   - –í—ã–±–µ—Ä–∏—Ç–µ "üß† –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è (U-Net)"
   - –ù–∞–∂–º–∏—Ç–µ "–û–±–∑–æ—Ä..." –∏ –≤—ã–±–µ—Ä–∏—Ç–µ `unet_cell_detector.onnx`
   - –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (confidence threshold, —Ä–∞–∑–º–µ—Ä—ã –∫–ª–µ—Ç–æ–∫)
   - –ù–∞–∂–º–∏—Ç–µ "–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"
   - –ù–∞—á–Ω–∏—Ç–µ –¥–µ—Ç–µ–∫—Ü–∏—é!

## –°–æ–≤–µ—Ç—ã –ø–æ –æ–±—É—á–µ–Ω–∏—é

### –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
- **–ú–∏–Ω–∏–º—É–º 50-100 —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π** –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
- **–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ**: —Ä–∞–∑–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è, –º–∞—Å—à—Ç–∞–±—ã, —É–≥–ª—ã
- **–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å**: –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å—Ç–∏–ª—å —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- **–ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤**: –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–µ—Ç–æ–∫ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞

### –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
- **Flip/Rotate**: –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã (–∫–ª–µ—Ç–∫–∏ –Ω–µ –∏–º–µ—é—Ç –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏)
- **Brightness/Contrast**: –ø–æ–ª–µ–∑–Ω—ã –¥–ª—è —Ä–∞–∑–Ω–æ–≥–æ –æ—Å–≤–µ—â–µ–Ω–∏—è
- **Elastic Transform**: –ø–æ–º–æ–≥–∞–µ—Ç —Å –¥–µ—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏
- **Cutout/GridMask**: —É–ª—É—á—à–∞–µ—Ç —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å

### –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
- **Learning Rate**: –Ω–∞—á–Ω–∏—Ç–µ —Å 1e-4, —É–º–µ–Ω—å—à–∏—Ç–µ –µ—Å–ª–∏ loss –Ω–µ –ø–∞–¥–∞–µ—Ç
- **Batch Size**: –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π, –∫–æ—Ç–æ—Ä—ã–π –≤–ª–µ–∑–∞–µ—Ç –≤ GPU
- **Input Size**: 512 (–±—ã—Å—Ç—Ä–æ) –∏–ª–∏ 1024 (—Ç–æ—á–Ω–µ–µ)
- **Epochs**: 50-100 –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ

### Overfitting
–ü—Ä–∏–∑–Ω–∞–∫–∏:
- Train loss –ø–∞–¥–∞–µ—Ç, –Ω–æ val loss —Ä–∞—Å—Ç–µ—Ç
- IoU –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–µ—Ä–µ—Å—Ç–∞–µ—Ç —Ä–∞—Å—Ç–∏

–†–µ—à–µ–Ω–∏—è:
- –ë–æ–ª—å—à–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
- Dropout –≤ decoder
- Weight decay (L2 regularization)
- Early stopping

### Underfitting
–ü—Ä–∏–∑–Ω–∞–∫–∏:
- –û–±–∞ loss –≤—ã—Å–æ–∫–∏–µ
- IoU < 0.5

–†–µ—à–µ–Ω–∏—è:
- –ë–æ–ª—å—à–µ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
- –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (ResNet50 –≤–º–µ—Å—Ç–æ ResNet34)
- –ú–µ–Ω—å—à–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–º–µ—Ç–∫–∏!

## Troubleshooting

### CUDA Out of Memory
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ batch_size –≤ config.yaml
batch_size: 2  # –±—ã–ª–æ 4

# –ò–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞
input_size: 512  # –±—ã–ª–æ 1024
```

### –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–∏
1. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ç–∫—É**: –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –º–∞—Å–∫–∏
2. **–£–≤–µ–ª–∏—á—å—Ç–µ –¥–∞–Ω–Ω—ã–µ**: –¥–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
3. **–ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤**: —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤—Å–µ —Ç–∏–ø—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã
4. **–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏**: –≤–∫–ª—é—á–∏—Ç–µ –±–æ–ª—å—à–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
5. **Fine-tuning**: –Ω–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤

### –ú–æ–¥–µ–ª—å –Ω–µ —Å—Ö–æ–¥–∏—Ç—Å—è
1. **Learning rate**: —É–º–µ–Ω—å—à–∏—Ç–µ –≤ 10 —Ä–∞–∑
2. **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è**: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ mean/std –¥–ª—è ImageNet
3. **Loss weights**: –æ—Ç—Ä–µ–≥—É–ª–∏—Ä—É–π—Ç–µ dice/bce –±–∞–ª–∞–Ω—Å
4. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π encoder

## –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥

```bash
# –ü–æ–ª–Ω—ã–π pipeline
python cvat_utils.py --format coco --input data/annotations.json --output data/masks/
python dataset.py --prepare-split --data-dir data/ --train-ratio 0.8
python train.py --config config.yaml
python export_onnx.py --checkpoint checkpoints/best_model.pth --output models/unet.onnx

# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –Ω–∞ 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
python train.py --config config.yaml --epochs 1 --batch-size 1
python export_onnx.py --checkpoint checkpoints/last.pth --output test.onnx --test-image data/images/test.jpg
```

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)
- [Albumentations](https://albumentations.ai/)
- [CVAT](https://github.com/opencv/cvat)
- [U-Net Paper](https://arxiv.org/abs/1505.04597)
- [Deep Learning for Cell Image Segmentation](https://www.nature.com/articles/s41592-021-01139-4)

## –ö–æ–Ω—Ç–∞–∫—Ç—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞

–ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã, —Å–æ–∑–¥–∞–π—Ç–µ issue –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤—ã—à–µ.
